CartPole-v1: &cartpole-defaults
  n_timesteps: !!float 5e5
  env_hyperparams:
    n_envs: 8
  rollout_hyperparams: &default-rollout
    include_logp: false
    n_steps: 5

CartPole-v0:
  <<: *cartpole-defaults

MountainCar-v0:
  n_timesteps: !!float 1e6
  env_hyperparams:
    n_envs: 16
    normalize: true
  rollout_hyperparams:
    <<: *default-rollout

MountainCarContinuous-v0:
  n_timesteps: !!float 1e5
  env_hyperparams:
    n_envs: 4
    normalize: true
  # policy_hyperparams:
  #   use_sde: true
  #   log_std_init: 0.0
  #   init_layers_orthogonal: false
  algo_hyperparams:
    sde_sample_freq: 16
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 100

Acrobot-v1:
  n_timesteps: !!float 5e5
  env_hyperparams:
    normalize: true
    n_envs: 16
  rollout_hyperparams:
    <<: *default-rollout

# Tuned
LunarLander-v2:
  device: cpu
  n_timesteps: !!float 1e6
  env_hyperparams:
    n_envs: 4
    normalize: true
  algo_hyperparams:
    gamma: 0.9955517404308908
    gae_lambda: 0.9875340918797773
    learning_rate: 0.0013814130817068916
    learning_rate_decay: linear
    ent_coef: !!float 3.388369146384422e-7
    ent_coef_decay: none
    max_grad_norm: 3.33982095073364
    normalize_advantage: true
    vf_coef: 0.1667838310548184
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 2

BipedalWalker-v3:
  n_timesteps: !!float 5e6
  env_hyperparams:
    n_envs: 16
    normalize: true
  policy_hyperparams:
    use_sde: true
    log_std_init: -2
    init_layers_orthogonal: false
  algo_hyperparams:
    ent_coef: 0
    max_grad_norm: 0.5
    gae_lambda: 0.9
    vf_coef: 0.4
    gamma: 0.99
    learning_rate: !!float 9.6e-4
    learning_rate_decay: linear
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 8

HalfCheetahBulletEnv-v0: &pybullet-defaults
  n_timesteps: !!float 2e6
  env_hyperparams:
    n_envs: 4
    normalize: true
  policy_hyperparams:
    use_sde: true
    log_std_init: -2
    init_layers_orthogonal: false
  algo_hyperparams: &pybullet-algo-defaults
    ent_coef: 0
    max_grad_norm: 0.5
    gae_lambda: 0.9
    gamma: 0.99
    vf_coef: 0.4
    learning_rate: !!float 9.6e-4
    learning_rate_decay: linear
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 8

AntBulletEnv-v0:
  <<: *pybullet-defaults

Walker2DBulletEnv-v0:
  <<: *pybullet-defaults

HopperBulletEnv-v0:
  <<: *pybullet-defaults

# Tuned
CarRacing-v0:
  n_timesteps: !!float 4e6
  env_hyperparams:
    n_envs: 4
    frame_stack: 4
    normalize: true
    normalize_kwargs:
      norm_obs: false
      norm_reward: true
  policy_hyperparams:
    use_sde: true
    log_std_init: -4.839609092563
    init_layers_orthogonal: true
    activation_fn: tanh
    share_features_extractor: false
    cnn_flatten_dim: 256
    hidden_sizes: [256]
  algo_hyperparams:
    learning_rate: 0.000018971962220405576
    gamma: 0.9942776405534832
    gae_lambda: 0.9549244758833236
    ent_coef: 0.0000015666550584860516
    ent_coef_decay: linear
    vf_coef: 0.12164696385898476
    max_grad_norm: 2.2574480552177127
    normalize_advantage: false
    use_rms_prop: false
    sde_sample_freq: 16
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 64

_atari: &atari-defaults
  n_timesteps: !!float 1e7
  env_hyperparams: &atari-env-defaults
    n_envs: 16
    frame_stack: 4
    no_reward_timeout_steps: 1000
    no_reward_fire_steps: 500
    vec_env_class: async
  policy_hyperparams: &atari-policy-defaults
    activation_fn: relu
  algo_hyperparams:
    ent_coef: 0.01
    vf_coef: 0.25
  rollout_hyperparams:
    <<: *default-rollout

Microrts-squnet-d16-128-BC-offline: &microrts-squnet-d16-128-bc-offline
  additional_keys_to_log:
    - microrts_stats
    - microrts_results
    - results
    - action_mask_stats
  algo_hyperparams: &microrts-squnet-d16-128-bc-offline-algo
    ent_coef: 0.0001
    gae_lambda: 0.99
    gamma: 0.999
    learning_rate: 1.0e-05
    learning_rate_decay: none
    max_grad_norm: 0.5
    normalize_advantage: false
    scale_loss_by_num_actions: true
    vf_coef: 0.5
    min_logprob: -3
  env_hyperparams:
    additional_win_loss_reward: false
    bots:
      coacAI: 12
      lightRushAI: 12
      mayari: 6
    env_type: microrts_bots
    make_kwargs:
      max_steps: 4000
      reward_weight:
        - 1.0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
        - 0
    map_paths:
      - maps/16x16/basesWorkers16x16A.xml
      - maps/16x16/TwoBasesBarracks16x16.xml
      - maps/8x8/basesWorkers8x8A.xml
      - maps/8x8/FourBasesWorkers8x8.xml
      - maps/NoWhereToRun9x8.xml
      - maps/16x16/EightBasesWorkers16x16.xml
    n_envs: 36
    reference_bot: mayari
    score_reward_kwargs: null
    self_play_kwargs: null
    valid_sizes:
      - 16
  env_id: Microrts-squnet-map16
  eval_hyperparams:
    deterministic: false
    env_overrides:
      additional_win_loss_reward: false
      bots:
        coacAI: 2
        droplet: 2
        guidedRojoA3N: 2
        izanagi: 2
        lightRushAI: 2
        mayari: 2
        mixedBot: 2
        naiveMCTSAI: 2
        passiveAI: 2
        randomAI: 2
        randomBiasedAI: 2
        rojo: 2
        tiamat: 2
        workerRushAI: 2
      env_type: microrts
      make_kwargs:
        bot_envs_alternate_player: false
        map_paths:
          - maps/16x16/basesWorkers16x16A.xml
        max_steps: 4000
        num_selfplay_envs: 0
        render_theme: 2
        reward_weight:
          - 1.0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
          - 0
      map_paths: []
      n_envs: 28
      score_reward_kwargs: {}
      self_play_kwargs: {}
    max_video_length: 4000
    n_episodes: 28
    score_function: mean
    skip_evaluate_at_start: true
    step_freq: 1000000.0
  n_timesteps: 100000000.0
  policy_hyperparams:
    activation_fn: relu
    actor_head_style: squeeze_unet
    additional_critic_activation_functions: []
    channels_per_level:
      - 128
      - 128
      - 128
    cnn_flatten_dim: 256
    cnn_style: microrts
    decoder_residual_blocks_per_level:
      - 2
      - 3
    deconv_strides_per_level:
      - - 2
        - 2
      - - 2
        - 2
    encoder_residual_blocks_per_level:
      - 3
      - 2
      - 4
    load_path: downloaded_models/acbc-Microrts-squnet-d16-128-iMayari-nondeterministic-S1-best
    output_activation_fn: tanh
    strides_per_level:
      - 4
      - 4
    subaction_mask:
      0:
        1: 1
        2: 2
        3: 3
        4: 4
        5: 4
        6: 5
  rollout_hyperparams:
    <<: *default-rollout
    n_steps: 96
    scale_advantage_by_values_accuracy: true
  hyperparam_transitions_kwargs:
    interpolate_method: cosine
    phases:
      - learning_rate: !!float 1e-5
        ent_coef: 0.01
      - learning_rate: !!float 1e-4
        ent_coef: 0.01
      - learning_rate: !!float 1e-5
        ent_coef: 0.0001
    durations:
      - 0
      - 0.05
      - 0.4
      - 0.35
      - 0.2
  rollout_type: reference

Microrts-squnet-d16-128-BC-offline-exp: &microrts-squnet-d16-128-bc-offline-exp
  <<: *microrts-squnet-d16-128-bc-offline
  algo_hyperparams:
    <<: *microrts-squnet-d16-128-bc-offline-algo
    min_logprob: null
    exp_logpa_loss: true

Microrts-debug:
  <<: *microrts-squnet-d16-128-bc-offline-exp
